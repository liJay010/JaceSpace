# SQL

## 数据库基础

### 1、关系型数据库范式

​		**应用数据库范式可以带来许多好处，但是最重要的好处归结为三点：**

​		1）减少数据冗余（这是最主要的好处，其他好处都是由此而附带的） 

​		2）消除异常（插入异常，更新异常，删除异常） 

​		3）让数据组织的更加和谐 

但是数据库范式绝对不是越高越好，范式越高，意味着表越多，多表联合查询的机率就越大，SQL的效 率就变低。

#### 第一范式（1NF）

​		**每一列保持原子特性**

​		列都是基本数据项，不能够再进行分割，否则设计成一对多的实体关系。例如表中的地址字段，可以再 细分为省，市，区等不可再分割（即原子特性）的字段。不符合第一范式不能称 作关系型数据库。

​		数据库表中的字段都是单⼀属性的，不可再分；每⼀个属性都是原⼦项，不可分割；如果实体中的某 个属性有多个值时，必须拆分为不同的属性 通俗解释。1NF是关系模式应具备的最起码的条件，如果数据库设计不 能满⾜第⼀范式，就不称为关系型数据库。也就是说，只要是关系型数据库，就⼀定满⾜第⼀范式。

#### 第二范式（2NF）

​		**属性完全依赖于主键    -   主要针对联合主键**

​		非主属性完全依赖于主关键字，如果不是完全依赖主键，应该拆分成新的实体，设计成一对多的实体关 系。

​		例如：选课关系表为SelectCourse(**学号**, 姓名, 年龄, **课程名称,** 成绩, 学分)，（学号，课程名称）是联合 主键，但是学**分字**段只和课程名称有关，和学号无关，相当于只依赖联合主键的其中一个字段，不符合 第二范式。



#### 第三范式（3NF）

​		**属性不依赖于其它非主属性**

​		要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。

​		示例：学生关系表为Student（**学号**， 姓名， 年龄， 所在学院， 学院地点， 学院电话），学号是主 键，但是学院电话只依赖于所在学院，并不依赖于主键学号，因此该设计不符合第三范式，应该把学院 专门设计成一张表，学生表和学院表，两个是一对多的关系。

​		注意：一般关系型数据库满足第三范式就可以了。



#### **BC范式（BCNF）**

​		**每个表中只有一个候选键**

#### 第四范式（4NF）

​		**消除表中的多值依赖**



### 2.数据库操作

​	SQL是结构化查询语言（Structure Query Language），它是关系型数据库的通用语言。

​	SQL主要可以划分为以下 3 个类别：

​		DDL（Data Definition Languages）语句 。数据定义语言，这些语句定义了不同的数据库、表、列、索引等数据库对象的定义。常用的语句关 键字主要包括 create、drop、alter等。

​		DML（Data Manipulation Language）语句。数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性，常用的语句关键字 主要包括 insert、delete、update 和select 等。

​		DCL（Data Control Language）语句 数据控制语句，用于控制不同的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户 的访问权限和安全级别。主要的语句关键字包括 grant、revoke 等。



#### **库操作**

```mysql
show databases; #查询数据库

create database ChatDB; #创建数据库		

drop database ChatDB; #删除数据库

use ChatDB; #选择数据库

```

#### **表操作**

```mysql
show tables; #查看表

create table user(id int unsigned primary key not null auto_increment,
	name varchar(50) not null,
	age tinyint not null,
	sex enum('M','W') not null)engine=INNODB default charset=utf8;#创建表

desc user;#查看表结构

show create table user\G   #查看建表sql

drop table user; # 删除表
```



#### CRUD操作



```mysql
#insert增加
insert into user(nickname, name, age, sex) values('fixbug', 'zhang san', 22,'M');
insert into user(nickname, name, age, sex) values('666', 'li si', 21, 'W'),('888', 'gao yang', 20, 'M');

#update修改
update user set age=23 where name='zhang san';
update user set age=age+1 where id=3;

#delete删除
delete from user where age=23;
delete from user where age between 20 and 22;
delete from user;

#select查询
select * from user;
select id,nickname,name,age,sex from user;
select id,name from user;
select id,nickname,name,age,sex from user where sex='M' and age>=20 and age<=25;
select id,nickname,name,age,sex from user where sex='M' and age between 20 and 25;
select id,nickname,name,age,sex from user where sex='W' or age>=22;

#去重distinct
select distinct name from user;

#空值查询 is [not] null
select * from user where name is null;

#union合并查询
SELECT expression1, expression2, ... expression_n
FROM tables[WHERE conditions]
UNION [ALL | DISTINCT] # 注意：union默认去重，不用修饰distinct，all表示显示所有重复值
SELECT expression1, expression2, ... expression_n
FROM tables[WHERE conditions];

SELECT country FROM Websites UNION ALL SELECT country FROM apps ORDER BY country;

#带in子查询  [NOT] IN(元素1，元素2，...，元素3)
select * from user where id in(10, 20, 30, 40, 50)
select * from user where id not in(10, 20, 30, 40, 50)
select * from user where id in(select stu_id from grade where average>=60.0)

#分页查询

select id,nickname,name,age,sex from user limit 10;
select id,nickname,name,age,sex from user limit 2000,10; #（从2000行开始，取10个）

#排序order by

select id,nickname,name,age,sex from user where sex='M' and age>=20 and age<=25 order by age asc;
select id,nickname,name,age,sex from user where sex='M' and age>=20 and age<=25 order by age desc;

#分组group by

select sex from user group by sex;
select count(id),sex from user group by sex;
select count(id),age from user group by age having age>20;


#字符串长度
select tweet_id from Tweets where length(content) > 15; //英文字符
select tweet_id from Tweets where char_length(content) > 15;  //英文字符 / 中文

#if条件 - 第一个为条件，第二个为对，第三个为否
IF(score >= 60, 'Pass', 'Fail') 

#日期相减操作，datediff，一个表使用两个查询 -- https://leetcode.cn/problems/rising-temperature/submissions/528278608/?envType=study-plan-v2&envId=sql-free-50
select a.id from Weather as a,
    Weather as b where datediff(a.recordDate,b.recordDate) = 1 and a.Temperature > b.Temperature;
    
#select子查询中需要进行对新select重命名
select c.machine_id , avg(c.time) as processing_time from (select a.machine_id,a.process_id,(b.timestamp - a.timestamp) as time from Activity as a,
    Activity as b where a.machine_id = b.machine_id and a.process_id = b.process_id and a.activity_type = "start"
    and b.activity_type = "end" ) as c group by c.machine_id;
    
#四舍五入保留
round(avg(c.time),3)
```

#### 连接查询

​	**内连接查询 相当于找到两个表的交的元素 以 两个表的相同元素链接 按照元素最少的链接**

```mysql

SELECT a.属性名1,a.属性名2,...,b,属性名1,b.属性名2... FROM table_name1 a inner join table_name2
b on a.id = b.id where a.属性名 满足某些条件;

select a.uid,a.name,a.age,a.sex,b.cid,b.cname,b.credit,c.score
from exame c
inner join student a on c.uid=a.uid
inner join course b on c.cid=b.cid
where c.cid=2 and c.score>=90.0;

```

​	**外连接查询** （左连接、右连接）

​	**左连接查询**

A 表，B表，寻找 A - A 交 B

```mysql
SELECT a.属性名列表, b.属性名列表 FROM table_name1 a LEFT [OUTER] JOIN table_name2 b on
a.id = b.id;

# 把left这边的表所有的数据显示出来，在右表中不存在相应数据，则显示NULL
select a.* from User a left outer join Orderlist b on a.uid=b.uid where a.orderid is null;
```

​	**右连接查询**

A 表，B表，寻找 B - A 交 B

```mysql
SELECT a.属性名列表, b.属性名列表 FROM table_name1 a RIGHT [OUTER] JOIN table_name2 b on a.id = b.id;
# 把right这边的表所有的数据显示出来，在左表中不存在相应数据，则显示NULL
select a.* from User a right outer join Orderlist b on a.uid=b.uid where b.orderid is null;

```



### 3.MySQL存储引擎

​		MyISAM 不支持事务、也不支持外键，索引采用非聚集索引，其优势是访问的速度快，对事务完整性没 有要求，以 SELECT、INSERT 为主的应用基本上都可以使用这个存储引擎来创建表。MyISAM的表在磁 盘上存储成 3 个文件，其文件名都和表名相同，扩展名分别是：

​		.frm（存储表定义）    .MYD（MYData，存储数据）    .MYI （MYIndex，存储索引）



​		InnoDB 存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全，支持自动增长列，外键等功能， 索引采用聚集索引，索引和数据存储在同一个文件，所以InnoDB的表在磁盘上有两个文件，其文件名 都和表名相同，扩展名分别是：

​		.frm（存储表的定义） .ibd（存储数据和索引）



​		MEMORY 存储引擎使用存在内存中的内容来创建表。每个MEMORY 表实际只对应一个磁盘文件，格式 是.frm（表结构定义）。MEMORY 类型的表访问非常快，因为它的数据是放在内存中的，并且默认使 用 HASH 索引（不适合做范围查询），但是一旦服务关闭，表中的数据就会丢失掉。

**各存储引擎区别**

![2](img\2.PNG)

**锁机制：**表示数据库在并发请求访问的时候，多个事务在操作时，并发操作的粒度。

**B-树索引和哈希索引：**主要是加速SQL的查询速度。

**外键：**子表的字段依赖父表的主键，设置两张表的依赖关系。

**事务：**多个SQL语句，保证它们共同执行的原子操作，要么成功，要么失败，不能只成功一部分，失败 需要回滚事务。

**索引缓存和数据缓存：**和MySQL Server的查询缓存相关，在没有对数据和索引做修改之前，重复查询 可以不用进行磁盘I/O（数据库的性能提升，目的是为了减少磁盘I/O操作来提升数据库访问效率），读 取上一次内存中查询的缓存就可以了。



### 4.MySQL索引

​		当表中的数据量到达几十万甚至上百万的时候，SQL查询所花费的时间会很长，导致业务超时出错，此 时就需要用索引来加速SQL查询。

​		由于索引也是需要存储成索引文件的，因此对索引的使用也会涉及磁盘I/O操作。如果索引创建过多， 使用不当，会造成SQL查询时，进行大量无用的磁盘I/O操作，降低了SQL的查询效率，适得其反，因此 掌握良好的索引创建原则非常重要！

#### 索引分类

​		索引是创建在表上的，是对数据库表中一列或者多列的值进行排序的一种结果。索引的核心是**提高查询 的速度**！

**物理上(聚集索引&非聚集索引)/逻辑上(...)**

**索引的优点： 提高查询效率**

**索引的缺点：** 索引并非越多越好，过多的索引会导致CPU使用率居高不下，由于数据的改变，会造成索 引文件的改动，过多的磁盘I/O造成CPU负荷太重



**1、普通索引：**没有任何限制条件，可以给任何类型的字段创建普通索引(创建新表&已创建表，数量是 不限的，一张表的一次sql查询只能用一个索引 where a=1 and b='M')

**2、唯一性索引：**使用UNIQUE修饰的字段，值不能够重复，主键索引就隶属于唯一性索引

**3、主键索引：**使用Primary Key修饰的字段会自动创建索引(MyISAM, InnoDB)

**4、单列索引：**在一个字段上创建索引

**5、多列索引：**在表的多个字段上创建索引 (uid+cid，多列索引必须使用到第一个列，才能用到多列索 引，否则索引用不上)

**6、全文索引：**使用FULLTEXT参数可以设置全文索引，只支持CHAR，VARCHAR和TEXT类型的字段 上，常用于数据量较大的字符串类型上，可以提高查询速度(线上项目支持专门的搜索功能，给后台服务 器增加专门的搜索引擎支持快速高校的搜索 elasticsearch 简称es C++开源的搜索引擎 搜狗的 workflow)



#### 索引创建和删除

**创建表的时候指定索引字段：**

```mysql
CREATE TABLE index1(id INT,
name VARCHAR(20),
sex ENUM('male', 'female'),
INDEX(id,name));

```

**在已经创建的表上添加索引：**

```mysql
CREATE [UNIQUE] INDEX 索引名 ON 表名（属性名（length） [ASC | DESC]);

#删除索引:

DROP INDEX 索引名 ON 表名;
```

**1.经常作为where条件过滤的字段考虑添加索引** 

**2.字符串列创建索引时，尽量规定索引的长度，而不能让索引值的长度key_len过长** 

**3.索引字段涉及类型强转、mysql函数调用、表达式计算等，索引就用不上了**



#### 索引的执行过程

**explain查看执行计划**

使用explain查看sql的执行计划，分析索引的执行过程，mysql的user权限表示例如下：

```mysql
mysql> explain select Host,User from user where Host='%'\G
*************************** 1. row ***************************
id: 1
select_type: SIMPLE
table: user
partitions: NULL
type: ref
possible_keys: PRIMARY
key: PRIMARY
key_len: 180
ref: const
rows: 1
filtered: 100.00
Extra: Using index
1 row in set, 1 warning (0.00 sec)
```

可以看到使用了主键索引，共扫描1行，Using index表示直接从索引树上查询到结果，**不需要回表**(回表是在索引就能查到数据，无需再查)。

**explain结果字段分析**

**select_type**
		simple：表示不需要union操作或者不包含子查询的简单select语句。有连接查询时，外层的查询为simple且只有一个。
		primary：一个需要union操作或者含有子查询的select，位于最外层的单位查询的select_type即为primary且只有一个。
		union：union连接的两个select查询，除了第一个表外，第二个以后的表的select_type都是union。
		union result：包含union的结果集，在union和union all语句中，因为它不需要参与查询，所以id字段为null。
**table**
		显示查询的表名；
		如果不涉及对数据库操作，这里显示null；
		如果显示为尖括号就表示这是个临时表，后边的N就是执行计划中的id，表示结果来自于这个查询产生的；
		如果是尖括号括起来\<union M,N\>也是一个临时表，表示这个结果来自于union查询的id为M，N的结果集；
**type**
		const：使用唯一索引或者主键，返回记录一定是1行记录的等值where条件时，通常type就是const。
		ref：常见于辅助索引的等值查找，或者多列主键、唯一索引中，使用第一个列之外的列作为等值查找会出现；返回数据不唯一的等值查找也会出现。
		range：索引范围扫描，常见于使用\<、\>、is null、between、in、like等运算符的查询中。
		index：索引全表扫描，把索引从头到尾扫一遍；常见于使用索引列就可以处理不需要读取数据文件的查询，可以使用索引排序或者分组的查询。
		all：全表扫描数据文件，然后在server层进行过滤返回符合要求的记录。
**ref**
		如果使用常数等值查询，这里显示const；
		如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段；
**Extra**
		using filesort：排序时无法用到索引，常见于order by和group by语句中。
		using index：查询时不需要回表查询，直接通过索引就可以获取查询的数据。



#### 索引的底层实现原理

​		数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘块（对应索引树的节点），索引树越低，越“矮胖”，磁盘IO次数就 少

​		MySQL支持两种索引，一种的B-树索引，一种是哈希索引，大家知道，B-树和哈希表在数据查询时的效 率是非常高的。

​		这里我们主要讨论一下MySQL InnoDB存储引擎，基于B-树（但实际上MySQL采用的是B+树结构）的 索引结构。

​		B-树是一种m阶平衡树，叶子节点都在同一层，由于每一个节点存储的数据量比较大，索引整个B-树的 层数是非常低的，基本上不超过三层。

​		由于磁盘的读取也是按block块操作的（内存是按page页面操作的），因此B-树的节点大小一般设置为 和磁盘块大小一致，这样一个B-树节点，就可以通过一次磁盘I/O把一个磁盘块的数据全部存储下来， 所以当使用B-树存储索引的时候，磁盘I/O的操作次数是最少的（MySQL的读写效率，主要集中在磁盘 I/O上）。

​		![B树](img\B树.PNG)

![B+](img\B+.PNG)

1. B-树的每一个节点，存了关键字和对应的数据地址，而**B+树的非叶子节点只存关键字**，**不存数据 地址**。因此B+树的每一个非叶子节点存储的关键字是远远多于B-树的，B+树的叶子节点存放关键 字和数据，因此，从树的高度上来说，B+树的高度要小于B-树，使用的磁盘I/O次数少，因此查询 会更快一些。
2. B-树由于每个节点都存储关键字和数据，因此离根节点进的数据，查询的就快，离根节点远的数 据，查询的就慢；B+树所有的数据都存在叶子节点上，因此在B+树上搜索关键字，找到对应数据 的时间是比较平均的，没有快慢之分。
3. 在B-树上如果做区间查找，遍历的节点是非常多的；**B+树所有叶子节点被连接成了有序链表结 构，因此做整表遍历和区间查找是非常容易的**。

哈希索引当然是由哈希表实现的，哈希表对数据并不排序，因此不适合做区间查找，效率非常低，需要 搜索整个哈希表结构。



#### 聚集和非聚集索引

​		**MyISAM**(**非聚集索引)**

**主键索引**

MyISAM引擎使用B+树作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM主键 索引的原理图：

![MYISAM索引](img\MYISAM索引.PNG)

**辅助索引**

​		在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯 一的，而辅助索引的key可以重复，如果给其它字段创建辅助索引，结构图如下:

![MYISAM索引2](img\MYISAM索引2.PNG)

根据上面两张图，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然 后以data域的值为地址，读取相应数据记录。

可以看到，MyISAM存储引擎，索引结构叶子节点存储关键字和数据地址，也就是说索引关键字和数据 没有在一起存放，体现在磁盘上，就是索引在一个文件存储，数据在另一个文件存储，例如一个user 表，会在磁盘上存储三个文件 user.frm（表结构文件） user.MYD（表的数据文件） user.MYI（表的 索引文件）。



**InnoDB(聚集索引)**

**主键索引**

InnoDB存储引擎的主键索引，叶子节点中，**索引关键字和数据是在一起存放的**，如图：

![INnoDb1](img\INnoDb1.PNG)

**辅助索引**

​		InnoDB的辅助索引，叶子节点上存放的是索引关键字和**对应的主键**，如图：

![innodb2](img\innodb2.PNG)

​		辅助索引的B+树，先根据关键字找到对应的主键，再去主键索引树上找到对应的行记录数据（回表）。从索引树 上可以看到，InnoDB的索引关键字和数据都是在一起存放的，体现在磁盘存储上，例如创建一个user 表，在磁盘上只存储两种文件，user.frm（存储表的结构），user.ibd（存储索引和数据）。

​		nnoDB的索引树叶节点包含了完整的数据记录，这种索引叫做聚集索引。因为InnoDB的数据文件本身 要按主键聚集，所以InnoDB要求表必须有主键（区别于MyISAM可以没有），如果没有显式指定，则 MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动 为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。



### 5.MySQL事务

#### 事务概念

​		一个事务是由一条或者多条对数据库操作的SQL语句所组成的一个不可分割的单元，只有当事务中的所 有操作都正常执行完了，整个事务才会被提交给数据库；如果有部分事务处理失败，那么事务就要回退 到最初的状态，因此，事务要么全部执行成功，要么全部失败。

所以记住事务的几个基本概念，如下：

​		1、事务是一组SQL语句的执行，要么全部成功，要么全部失败，不能出现部分成功，部分失败的结 果。保证事务执行的原子操作。

​		2、事务的所有SQL语句全部执行成功，才能提交（commit）事务，把结果写回磁盘上。

​		3、事务执行过程中，有的SQL出现错误，那么事务必须要回滚（rollback）到最初的状态。

#### **ACID特性**

每一个事务必须满足下面的4个特性：

**事务的原子性（Atomic）：**
		事务是一个不可分割的整体，事务必须具有原子特性，及当数据修改时，要么全执行，要么全不执行，即不允许事务部分的完成。

**事务的一致性（Consistency）：**
		一个事务执行之前和执行之后，数据库数据必须保持一致性状态。数据库的一致性状态必须由用户来负责，由并发控制机制实现。就拿网上购物来说，你只有让商品出库，又让商品进入顾客的购物车才能构成一个完整的事务。

**事务的隔离性（Isolation）：**
		当两个或者多个事务并发执行时，为了保证数据的安全性，将一个事物内部的操作与其它事务的操作隔离起来，不被其它正在执行的事务所看到，使得并发执行的各个事务之间不能互相影响。

**事务的持久性（Durability）：**
		事务完成(commit)以后，DBMS保证它对数据库中的数据的修改是永久性的，即使数据库因为故障出错，也应该能够恢复数据！



#### 事务并发存在的问题

事务处理不经隔离，并发执行事务时通常会发生以下的问题：

​		**脏读（Dirty Read）：**一个事务读取了另一个事务**未提交的数据**。例如当事务A和事务B并发执行时，当 事务A更新后，事务B查询读取到A尚未提交的数据，此时事务A回滚，则事务B读到的数据就是无效的脏 数据。（事务B读取了事务A尚未提交的数据）

​		**不可重复读（NonRepeatable Read）：**一个事务的操作导致另一个事务前后两次读取到不同的数据。 例如当事务A和事务B并发执行时，当事务B查询读取数据后，事务A更新操作更改事务B查询到的数据， 此时事务B再次去读该数据，发现前后两次读的数据不一样。（事务B读取了事务A已提交的数据）

​		**虚读（Phantom Read）幻读：**一个事务的操作导致另一个事务前后两次查询的结果数据量不同。例如 当事务A和事务B并发执行时，当事务B查询读取数据后，事务A新增或者删除了一条满足事务B查询条件 的记录，此时事务B再去查询，发现查询到前一次不存在的记录，或者前一次查询的一些记录不见了。 （事务B读取了事务A新增加的数据或者读不到事务A删除的数据）



#### 事务的隔离级别

MySQL支持的四种隔离级别是：
		1、TRANSACTION_READ_UNCOMMITTED。**未提交读**。说明在提交前一个事务可以看到另一个事务的变化。这样读脏数据，不可重复读和虚读都是被允许的。
		2、TRANSACTION_READ_COMMITTED。**已提交读**。说明读取未提交的数据是不允许的。这个级别仍然允许不可重复读和虚读产生。
		3、TRANSACTION_REPEATABLE_READ。**可重复读**。说明事务保证能够再次读取相同的数据而不会失败，但虚读仍然会出现。
		4、TRANSACTION_SERIALIZABLE。**串行化**。是最高的事务级别，它防止读脏数据，不可重复读和虚读。

​		事务隔离级别越高，为避免冲突所花费的性能也就越多。 在“可重复读”级别，实际上可以解决部分的虚读问题，但是不能防止update更新产生的虚读问题，要禁 止虚读产生，还是需要设置串行化隔离级别。

#### MySQL的事务处理命令

打开MySQL的Command命令行窗口，测试以下命令：

1、SELECT @@AUTOCOMMIT; 查看MySQL是否自动提交事务

```mysql
mysql> select @@autocommit;
+--------------+
| @@autocommit |
+--------------+
| 1 |
+--------------+
1 row in set (0.00 sec)

```

0表示手动提交事务，1表示自动提交事务，设置事务提交方式为手动提交方式：

```mysql
mysql> set autocommit=0;
Query OK, 0 rows affected (0.00 sec)

```

```mysql
BEGIN; 开启一个事务
COMMIT; 提交一个事务
ROLLBACK; 回滚一个事务到初始的位置
SAVEPOINT point1; 设置一个名字为point1的保存点
ROLLBACK TO point1; 事务回滚到保存点point1，而不是回滚到初始状态
SET TX_ISOLATION='REPEATABLE-READ'; 设置事务的隔离级别
SELECT @@ TX_ISOLATION; 查询事务的隔离级别
```



### 6.MySQL的锁机制

#### **表级锁&行级锁**

​		表级锁：对整张表加锁。开销小，加锁快，不会出现死锁；锁粒度大，发生锁冲突的概率高，并发度 低。 

​		行级锁：对某行记录加锁。开销大，加锁慢，会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并 发度高。



#### **排它锁和共享锁**

**排它锁（Exclusive），又称为X 锁，写锁。**
**共享锁（Shared），又称为S 锁，读锁。**
X和S锁之间有以下的关系： SS可以兼容的，XS、SX、XX之间是互斥的
		一个事务对数据对象 O 加了 S 锁，可以对 O 进行读取操作但不能进行更新操作。加锁期间其它事务能对O 加 S 锁但不能加 X 锁。
		一个事务对数据对象 O 加了 X 锁，就可以对 O 进行读取和更新。加锁期间其它事务不能对 O 加任何锁。
		显示加锁：**select ... lock in share mode强制获取共享锁，select ... for update获取排它锁**



#### InnoDB行级锁

​		InnoDB存储引擎支持事务处理，表支持**行级锁定**，并发能力更好。

​		1、InnoDB行锁是通过给索引上的**索引项加锁**来实现的，而不是给表的行记录加锁实现的，这就意味着只有通过索引条件检索数据，InnoDB才使用行级锁，**否则InnoDB将使用表锁**。
​		2、由于InnoDB的行锁实现是针对索引字段添加的锁，不是针对行记录加的锁，因此虽然访问的是InnoDB引擎下表的不同行，**但是如果使用相同的索引字段作为过滤条件**，依然会发生锁冲突，只能串行进行，不能并发进行。
​		3、即使SQL中使用了索引，但是经过MySQL的优化器后，如果认为全表扫描比使用索引效率更高，此时会放弃使用索引，因此也不会使用行锁，而是使用表锁，比如对一些很小的表，MySQL就不会去使用索引。



#### 间隙锁

​		当我们用**范围条件**而不是相等条件检索数据，并请求共享或排他锁时，InnoDB 会给符合条件的**已有数据记录的索引项加锁**；对于**键值在条件范围内但并不存在的记录，叫做“间隙（GAP)” ，InnoDB 也会对这个“间隙”加锁**，这种锁机制就是所谓的间隙锁。举例来说， 假如 user 表中只有 101 条记录， 其userid 的值分别是 1,2,...,100,101， 下面的 SQL：

```mysql
select * from user where userid > 100 for update;
```

​		是一个范围条件的检索，InnoDB 不仅会对符合条件的 userid 值为 101 的记录加锁，也会对userid 大于 101（但是这些记录并不存在）的"间隙"加锁，防止其它事务在表的末尾增加数据。InnoDB使用间隙锁的目的，为了防止幻读，以满足串行化隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其他事务插入了 userid 大于 100 的任何记录，那么本事务如果再次执行上述语句，就会发生幻读。间隙锁是对每个索引元素中间的”间隙“加的，保持**左闭右开原则**。



#### 意向共享锁和意向排他锁

​		用来快速获取表锁。

​		**意向共享锁（IS锁）：**事务计划给记录加行共享锁，事务在给一行记录加共享锁前，必须先取得该表的 IS 锁。

​		**意向排他锁（IX锁）：**事务计划给记录加行排他锁，事务在给一行记录加排他锁前，必须先取得该表的 IX 锁。

1、意向锁是由InnoDB存储引擎获取行锁之前自己获取的
2、意向锁之间都是兼容的，不会产生冲突
3、**意向锁存在的意义是为了更高效的获取表锁**
4、意向锁是表级锁，协调表锁和行锁的共存关系。主要目的是显示事务正在锁定某行或者试图锁定某行。 



#### InnoDB表级锁

​		在绝大部分情况下都应该使用行锁，因为事务和行锁往往是选择InnoDB的理由，但个别情况下也使用 表级锁；

​		1）事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间等待和锁冲突；
​		2）事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。 
如：
​		LOCK TABLE user READ；读锁锁表
​		LOCK TABLE user WRITE; 写锁锁表
事务执行...
​		COMMIT/ROLLBACK; 事务提交或者回滚
​		UNLOCK TABLES; 本身自带提交事务，释放线程占用的所有表锁 



#### **死锁**

​		MyISAM 表锁是 deadlock free 的， 这是因为 MyISAM 总是一次获得所需的全部锁，要么全部满足， 要么等待，因此不会出现死锁。但在 InnoDB 中，除单个 SQL 组成的事务外，锁是逐步获得的，即锁 的粒度比较小，这就决定了在 InnoDB 中发生死锁是可能的。

​		死锁问题一般都是我们自己的应用造成的，和多线程编程的死锁情况相似，大部分都是由于我们多个线 程在获取多个锁资源的时候，获取的顺序不同而导致的死锁问题。因此我们应用在对数据库的多个表做 更新的时候，不同的代码段，应对这些表按相同的顺序进行更新操作，以防止锁冲突导致死锁问题。 

**锁的优化建议**

1.尽量使用较低的隔离级别
2.设计合理的索引并尽量使用索引访问数据，使加锁更加准确，减少锁冲突的机会提高并发能力
3.选择合理的事务大小，小事务发生锁冲突的概率小
4.不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序
存取表中的行。这样可以大大减少死锁的机会
5.尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响
6.不要申请超过实际需要的锁级别
7.除非必须，查询时不要显示加锁 



### 7.MVCC多版本并发控制


​	乐观锁和悲观锁是并发控制的两种不同策略，用于处理多个事务同时访问共享资源可能引发的数据一致性问题。它们在处理并发访问时采用了不同的思想和实现方式。

####  乐观锁

- **思想：** 假设并发冲突的概率较低，事务在读取数据时不会对数据进行加锁，而是在更新数据时检查是否有其他事务已经修改了数据。
- **实现方式：** 通过版本号（或时间戳）来实现。每个数据项都有一个版本号，事务在读取数据时会记录当前版本号，在更新数据时只有在版本号没有发生变化的情况下才会进行更新，否则会认为数据已经被其他事务修改，需要进行冲突处理。
- **优点：** 适用于读操作频繁、写操作较少的场景，减少了对数据的加锁操作，提高了并发性能。
- **缺点：** 在并发冲突概率较高时可能导致冲突较多，需要进行回滚和重试操作，增加了复杂性。

#### 悲观锁

- **思想：** 假设并发冲突概率较高，事务在读取数据时会对数据进行加锁，确保在事务完成之前其他事务无法修改该数据。
- **实现方式：** 使用数据库提供的锁机制，如行级锁或表级锁。在事务读取数据时，对相关数据进行锁定，其他事务必须等待锁被释放才能访问相同数据。
- **优点：** 确保事务之间的数据一致性，避免了并发冲突问题。
- **缺点：** 降低了并发性能，因为在事务读取数据期间其他事务无法访问相同数据，可能导致性能瓶颈。

#### 总结

- 乐观锁适用于并发冲突概率较低的情况，通过版本号等方式实现，提高了并发性能。
- 悲观锁适用于并发冲突概率较高的情况，通过锁机制确保数据的一致性，但可能降低并发性能。

在实际应用中，选择乐观锁还是悲观锁取决于业务场景和对并发性能和数据一致性的要求。有时候也会结合使用两者，例如在乐观锁的基础上使用悲观锁进行额外的冲突处理。

​		MVCC是多版本并发控制（Multi-Version Concurrency Control，简称MVCC），是MySQL中基于乐观锁理论实现隔离级别的方式，用于实现已提交读和可重复读隔离级别的实现，也经常称为多版本数据库。MVCC机制会生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本（系统版本号和事务版本号）。
​		MVCC多版本并发控制中，读操作可以分为两类：

**1、快照读（snapshot read）**

​		读的是记录的可见版本，不用加锁。就是事务begin() 或者修改的一个快照。



**2、当前读（current read）**

​		读取的是记录的最新版本，并且当前读返回的记录。

​		MVCC：每一行记录实际上有多个版本，每个版本的记录除了数据本身之外，增加了其它字段
​		**DB_TRX_ID：**记录当前事务ID
**DB_ROLL_PTR：**指向undo log日志上数据的指针

**已提交读：**每次**执行语句的时候**都重新生成一次快照（Read View），每次select查询时。
**可重复读：**同一个事务开始begin的时候生成一个当前事务全局性的快照（Read View），第一次select查询时。

快照内容读取原则：
1、版本未提交无法读取生成快照
2、版本已提交，但是在快照创建后提交的，无法读取
3、版本已提交，但是在快照创建前提交的，可以读取
4、当前事务内自己的更新，可以读到



### 8.MySQL优化

**SQL和索引优化**

**连接池**

​		应用上一般访问数据库，都是先和MySQL Server创建连接，然后发送SQL语句，Server处理完成后， 再把结果通过网络返回给应用，然后关闭和MySQL Server的连接，因此短时间大量的数据库访问，消 耗的TCP三次握手和四次挥手所花费的时间就很大了，稍微大一点的项目，我们都会在应用访问数据库 的那一层上，添加连接池模块，相当于应用和MySQL Server事先创建一组连接，当应用需要请求 MySQL Server时，不需要再进行TCP连接和释放连接了，一般连接池都会维护以下资源：

​		1、连接池里面保持固定数量的活跃TCP连接，供应用使用。 

​		2、如果应用瞬间访问MySQL的量比较大，那么连接池会实时创建更多的连接给应用使用。 

​		3、当连接池里面的TCP连接一段时间内没有被用到，连接池会释放多余的连接资源，保留它设置的最 大空闲连接量就可以了。

**增加cache缓存层**

​		业务上增加redis、memcache，一般用缓存把经常访问的数据缓存起来。

**MySQL Server优化**

​		对于MySQL Server端的优化，主要指的就是MySQL Server启动时加载的配置文件的配置项内容的优化 （就是那个my.ini或者my.cnf），下面我们看看它的配置文件中有哪些是我们需要重点关注的优化参 数。

**MySQL查询缓存**

​		MySQL的查询缓存是把select查询语句上一次的查询结果记录下来放在缓存当中，下一次再查询相同内 容的时候，直接从缓存中取出来就可以了，不用再进行一遍真正的SQL查询。但是当两个select查询中 间出现insert，update，delete语句的时候，查询缓存就会被清空。查询缓存适用更新不频繁的表，因 为当表更新频繁的话，查询缓存也总是被清空，过多的查询缓存的数据添加和删除，就会影响MySQL的 执行效率，还不如每次都从磁盘上查来得快（缓存指的就是一块内存，内存I/O比磁盘I/O快很多）。

**索引和数据缓存**

​		主要指的就是innodb_buffer_pool_size配置项，从名字上就能看到，该配置项是针对InnoDB存储引擎 起作用的，这个参数定义了InnoDB 存储引擎的表数据和索引数据的最大内存缓冲区大小。 innodb_buffer_pool_size是同时为数据块和索引块做缓存，这个值设得越高，访问表中数据需要的磁 盘 I/O 就越少。

**MySQL线程缓存**

​		主要指配置文件中thread_cache_size配置项。给大家讲过MySQL Server网络模块采用经典的I/O复用 +线程池模型，之所以引入线程池，主要就是为了在业务执行的过程中，不会因为临时创建和销毁线 程，造成系统性能降低，因为线程的创建和销毁是很耗费性能的，所以线程池就是在业务使用之前，先 创建一组固定数量的线程，等待事件发生，当有SQL请求到达MySQL Server的时候，在线程池中取一 个线程来执行该SQL请求就可以了，执行完成后，不销毁线程，而是把线程再归还到线程池中，等待下 一次任务的处理（MySQL会根据连接量，自动加大线程池的数量）。

**并发连接数量和超时时间**

​		MySQL Server作为一个服务器，可以设置客户端的最大连接量和连接超时时间，如果数据库连接统计 数量比较大，这两个参数的值需要设置大一些。



### 9.MySQL日志

#### 错误日志

​		错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程 中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日 志。

​		mysqld 使用错误日志名 host_name.err(host_name 为主机名) 并默认在参数 DATADIR(数据目录)指定 的目录中写入日志文件。



#### 查询日志

​		查询日志记录了客户端的所有语句。由于上线项目sql特别多，开启查询日志IO太多导致MySQL效率 低，只有在调试时才开启，比如通过查看sql发现热点数据进行缓存。

```mysql
mysql> show global variables like "%genera%";
```

​		

​	

#### 二进制日志

​		二进制日志(BINLOG)记录了所有的 DDL(数据定义语言)语句和 DML(数据操纵语言) 语句，但是不包括 数据查询语句。语句以“事件”的形式保存，它描述了数据的更改过程。 此日志对于灾难时的数据恢复起 着极其重要的作用。

两个重要的应用场景：**主从复制、数据恢复**

​		

#### 慢查询日志

​		MySQL可以设置慢查询日志，当SQL执行的时间超过我们设定的时间，那么这些SQL就会被记录在慢查 询日志当中，然后我们通过查看日志，用explain分析这些SQL的执行计划，来判定为什么效率低下，是 没有使用到索引？还是索引本身创建的有问题？或者是索引使用到了，但是由于表的数据量太大，花费 的时间就是很长，那么此时我们可以把表分成n个小表，比如订单表按年份分成多个小表等。

#### redo log和undo log

**redo log**

​		**redo log：**重做日志，用于记录事务操作的变化，确保事务的持久性。redo log是在事务开始后就开始记录，不管事务是否提交都会记录下来，在异常发生时（如数据持久化过程中掉电），InnoDB会使用redo log恢复到掉电前的时刻，保证数据的完整性。

​		innodb_log_buffer_size默认是16M，就是redo log缓冲区的大小，它随着事务开始，就开始写redolog，如果事务比较大，为了
避免事务执行过程中花费过多磁盘IO，可以设置比较大的redo log缓存，节省磁盘IO。

​		InnoDB修改操作数据，不是直接修改磁盘上的数据，实际只是修改Buffer Pool中的数据。InnoDB总是
先把Buffer Pool中的数据改变记录到redo log中，用来进行崩溃后的数据恢复。 优先记录redo log，然后再慢慢的将Buffer Pool中的脏数据刷新到磁盘上。

​		innodb_log_group_home_dir指定的目录下的两个文件：ib_logfile0，ib_logfile1，该文件被称作重做日志。
buffer pool缓存池：

​		作用：加速读和加速写，直接操作data page，写redo log修改就算完成，有专门的线程去做把bufferpool中的dirty page写入磁盘。



![redolong](img\redolong.PNG)

**undo log**

​		undo log：回滚日志，保存了事务发生之前的数据的一个版本，用于事务执行时的回滚操作，同时也是 实现多版本并发控制（MVCC）下读操作的关键技术。

DB_TRX_ID:事务ID DB_ROLL_PTR:回滚指针

![undolong](img\undolong.PNG)

### 10.数据备份

```sh
#数据备份恢复常用命令
mysqldump -u root -p123456 --all-databases > ~/all.sql
mysqldump -u root -p123456 --databases school > ~/school.sql
mysqldump -u root -p123456 school user > ~/user.sql
mysql -u root -p123456 -D school -e 'select * from user where age>18' > ~/user_data.txt
source ~/school.sq
```

### 11.MySQL集群

​		在实际生产环境中，如果对mysql数据库的读和写都在一台数据库服务器中操作，无论是在安全性、高 可用性，还是高并发等各个方面都是不能满足实际需求的，一般要通过主从复制的方式来同步数据，再 通过读写分离来提升数据库的并发负载能力。

1、数据备份 - 热备份&容灾&高可用 

2、读写分离，支持更大的并发

#### 主从复制

![主从复制](img\主从复制.PNG)

#### 读写分离

​		读写分离就是在主服务器上修改，数据会同步到从服务器，从服务器只能提供读取数据，不能写入，实 现备份的同时也实现了数据库性能的优化，以及提升了服务器安全。

![读写分离](img\读写分离.PNG)

目前较为常见的MySQL读写分离方式有： 

​		程序代码内部实现 

​		引入中间代理层 （MySQL_proxy、Mycat）

### 12.MySQL分库分表

​		刚开始多数项目用单机数据库就够了，随着服务器流量越来越大，面对的请求也越来越多，我们做了数 据库读写分离， 使用多个从库副本（Slave）负责读，使用主库（Master）负责写，master和slave通 过主从复制实现数据同步更新，保持数据一致。slave 从库可以水平扩展，所以更多的读请求不成问 题。

​		但是当用户量级上升，写请求越来越多，怎么保证数据库的负载足够？增加一个Master是不能解决问题 的， 因为数据要保存一致性，写操作需要2个master之间同步，相当于是重复了，而且架构设计更加复 杂。

​		这时需要用到分库分表（sharding），对写操作进行切分。



**单库太大**

​		单库处理能力有限、所在服务器上的磁盘空间不足、遇到IO瓶颈，需要把单库切分成更多更小的库

**单表太大**

​		CURD效率都很低、数据量太大导致索引膨胀、查询超时，需要把单表切分成多个数据集更小的表

**拆分策略**

​	单个库太大，先考虑是表多还是数据多：   

​		如果因为表多而造成数据过多，则使用垂直拆分，即根据业务拆分成不同的库 

​		如果因为单张表的数据量太大，则使用水平拆分，即把表的数据按照某种规则拆分成多张表 

分库分表的原则应该是先考虑垂直拆分，再考虑水平拆分。



**垂直分表** 

​		也就是“大表拆小表”，基于列字段进行。 一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对几百列的这种大表，也避免查询时，数据量太大造成的“跨页”问题。

**垂直分库**

​		垂直分库针对的是一个系统中的不同业务进行拆分。

​		比如用户User一个库，商品Product一个库，订单Order一个库， 切分后，要放在多个服务器上，而不 是一个服务器上。想象一下，一个购物网站对外提供服务，会有用户，商品，订单等的CRUD。没拆分 之前， 全部都是落到单一的库上的，这会让数据库的单库处理能力成为瓶颈。按垂直分库后，如果还是放在一个数据库服务器上， 随着用户量增大，这会让单个数据库的处理能力成为瓶颈，还有单个服务器 的磁盘空间，内存，tps等非常吃紧。 所以我们要拆分到多个服务器上，这样上面的问题都解决了，以 后也不会面对单机资源问题。

​		数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理， 维护，监控，扩展等。 数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于 Web和应用服务器来讲，是比较难实现“横向扩展”的。 数据库的连接资源比较宝贵且单机处理能力也有 限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。

**水平分表**

​		针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面 去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈，不建议采用。



**水平分库分表**

​		将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平 分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。



## 问题

### 1、关系型和非关系型数据库的区别你了解多少？

- 关系型数据库的优点
  - 容易理解。因为它采用了关系模型来组织数据。
  - 可以保持数据的一致性。
  - 数据更新的开销比较小。
  - 支持复杂查询（带where子句的查询）
- 非关系型数据库的优点
  - 不需要经过SQL层的解析，读写效率高。
  - 基于键值对，数据的扩展性很好。
  - 可以支持多种类型数据的存储，如图片，文档等等。



### 2、什么是非关系型数据库？

非关系型数据库也叫NOSQL，采用键值对的形式进行存储。

它的读写性能很高，易于扩展，可分为内存性数据库以及文档型数据库，比如 Redis，Mongodb，HBase等等。

适合使用非关系型数据库的场景：

- 日志系统
- 地理位置存储
- 数据量巨大
- 高可用



### 3、为什么使用索引？

- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
- 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。
- 帮助服务器避免排序和临时表
- 将随机IO变为顺序IO。
- 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义

### 4、Innodb为什么要用自增id作为主键？

如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置， 频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE（optimize table）来重建表并优化填充页面。

### 5、MyISAM和InnoDB实现B树索引方式的区别是什么？

- MyISAM，B+Tree叶节点的data域存放的是数据记录的地址，在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的key存在，则取出其data域的值，然后以data域的值为地址读取相应的数据记录，这被称为“非聚簇索引”

- InnoDB，其数据文件本身就是索引文件，相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的节点data域保存了完整的数据记录，这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引，这被称为“聚簇索引”或者聚集索引，而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。

  在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议使用过长的字段为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。

### 6、说一下MySQL是如何执行一条SQL的？具体步骤有哪些？

![SQL执行的全部过程](http://oss.interviewguide.cn/img/202205220024265.png)

Server层按顺序执行sql的步骤为：

1. 客户端请求
2. 连接器（验证用户身份，给予权限）
3. 查询缓存（存在缓存则直接返回，不存在则执行后续操作）
4. 分析器（对SQL进行词法分析和语法分析操作） 
5. 优化器（主要对执行的sql优化选择最优的执行方案方法） 
6. 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）
7. 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）

简单概括：

- **连接器**：管理连接、权限验证；
- **查询缓存**：命中缓存则直接返回结果；
- **分析器**：对SQL进行词法分析、语法分析；（判断查询的SQL字段是否存在也是在这步）
- **优化器**：执行计划生成、选择索引；
- **执行器**：操作引擎、返回结果；
- **存储引擎**：存储数据、提供读写接口。

### 7、听说过视图吗？那游标呢？

视图是一种虚拟的表，通常是有一个表或者多个表的行或列的子集，具有和物理表相同的功能 游标是对查询出来的结果集作为一个单元来有效的处理。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。

### 8、数据库悲观锁和乐观锁的原理和应用场景分别有什么？

悲观锁，先获取锁，再进行业务操作，一般就是利用类似 SELECT … FOR UPDATE 这样的语句，对数据加锁，避免其他事务意外修改数据。 当数据库执行SELECT … FOR UPDATE时会获取被select中的数据行的行锁，select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。

乐观锁，先进行业务操作，只在最后实际更新数据时进行检查数据是否被更新过。Java 并发包中的 AtomicFieldUpdater 类似，也是利用 CAS 机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，来实现乐观锁需要的版本判断。

### [9、覆盖索引是什么？](https://github.com/forthespada/InterviewGuide/blob/main/docs/notes/03-hunting_job/02-interview/04-01-02-MySQL.md#26覆盖索引是什么)

如果一个索=引包含（或者说覆盖）所有需要查询的字段的值，我们就称 之为“覆盖索引”。

我们知道在InnoDB存储引 擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次,这样就 会比较慢。覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！