# layoutLM3训练问题解决

## 0.环境配置

严格按照如下配置，特别是torch1.10，且尽量cuda等于11.1

[unilm/layoutlmv3 at master · microsoft/unilm · GitHub](https://github.com/microsoft/unilm/tree/master/layoutlmv3)

```sh
pip install setuptools==59.5.0
pip install protobuf==3.20.1  -i https://pypi.douban.com/simple/
```

【448，448】 -\> (1,3,1088,768)

【224，224】 -\> (1,3,1088,768)

## 1.数据集配置

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/train_net.py

中修改注册数据集，COCO数据集

```py
    #注释其他数据集
    
 register_coco_instances("publaynet_train", {}, "/data1/lxj/workspace/layout/dataset/COCO/train/annotations.json", "/data1/lxj/workspace/layout/dataset/COCO/train")
    register_coco_instances("publaynet_val", {}, "/data1/lxj/workspace/layout/dataset/COCO/val/annotations.json", "/data1/lxj/workspace/layout/dataset/COCO/val")



```

## 2.训练

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml

NUM_CLASSES: 10

IMS_PER_BATCH: 1

```sh
cd /data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection


python train_net.py --config-file cascade_layoutlmv3.yaml --num-gpus 4 MODEL.WEIGHTS /data1/lxj/workspace/layout/model/layoutlmv3-base-chinese/pytorch_model.bin OUTPUT_DIR /data1/lxj/workspace/layout/output/12-14
```



# 3.batchsize以及step

**源论文：**

**16GPU**（具体不知道）

PubLayNet数据集：335,703图像

batchsize：32

step：60000，1,000 warmup

eopch约6轮



420 2080ti：

CDLA_DATASET：5000训练图像

4张卡一共能设置最大batchsize：4

step：60000，1,000 warmup



# 4.测试

测试中需要json文件

```sh
python train_net.py --config-file cascade_layoutlmv3.yaml --eval-only --num-gpus 4 \
        MODEL.WEIGHTS /data1/lxj/workspace/layout/output/model_final.pth \
        OUTPUT_DIR /data1/lxj/workspace/layout/output/val
```

# 5.网络问题

```sh
export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890
```

# 6.多模态训练方法

## 1.更改backbone.py

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/ditod/backbone.py

```py
#self.backbone = LayoutLMv3Model(config, detection=True,
#                                   out_features=out_features, image_only=image_only)
#将image_only改为false
self.backbone = LayoutLMv3Model(config, detection=True,
                                   out_features=out_features,image_only=False)
```

## 2.更改rcnn_vl.py

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/ditod/rcnn_vl.py

```py
    #将get_batch函数替换
def get_batch(self, examples, images):

    if len(examples) >= 1 and "bbox" not in examples[0]:  # image_only

        ids = torch.stack([i['input_id'] for i in examples],dim=0).to(images.device)
        box = torch.stack([i['box'] for i in examples],dim=0).to(images.device)
        return {"images": images.tensor,"input_ids":ids,"bbox":box}

    return input
```

## 3.更改dataset_mapper.py

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/ditod/dataset_mapper.py

```py
dataset_dict["image"] = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))
dataset_dict["input_id"] = torch.tensor([45,65]) #这里是输入的ids
dataset_dict["box"] = torch.tensor([[1,2,3,4],[4,5,6,7]])#这里是输入的box
```

## 4.中文的token分词器

```py
from transformers import AutoTokenizer

tokenizer=AutoTokenizer.from_pretrained("yuyijiong/layoutlmv3-base-chinese-xfund")
tokens=tokenizer.tokenize("你好，我叫李兴杰")
token_ids = tokenizer.convert_tokens_to_ids(tokens)
print(token_ids)

#tokenizer.convert_tokens_to_string(tokens)
#tokenizer.encode(sentence)
#tokenizer.decode(token_ids,skip_special_tokens=False)
```

## 5.OCR

```py
import os
from PIL import Image
import json
from paddleocr import PaddleOCR, draw_ocr
ocr = PaddleOCR(use_angle_cls=True, lang="ch")
def perform_ocr(image_path):
    # 假设这里调用你的OCR函数并返回bbox和words列表
    # 实际情况需要替换为你的OCR函数调用
    print("process:"+image_path)
    result = ocr.ocr(image_path, cls=True)
    result = result[0]

    bbox=[[line[0][0][0],line[0][0][1],line[0][2][0]-line[0][0][0],line[0][2][1]-line[0][0][1]] for line in result]

    words = [line[1][0] for line in result] # 示例words
    return bbox, words

def process_images(folder_path):
    for filename in os.listdir(folder_path):
        if filename.endswith(('.jpg', '.jpeg', '.png')):  # 假设你处理的是图片文件
            image_path = os.path.join(folder_path, filename)

            # 调用OCR函数
            bbox, words = perform_ocr(image_path)

            # 获取图片分辨率
            with Image.open(image_path) as img:
                w, h = img.size

            # 构建结果字典
            result = {
                    "bbox": bbox,
                    "words": words,
                    "W": w,
                    "H": h
            }

            # 保存为JSON文件
            json_filename = os.path.splitext(filename)[0] + ".json"
            json_path = os.path.join(folder_path, json_filename)

            with open(json_path, 'w',encoding='utf-8') as json_file:
                json.dump(result, json_file, ensure_ascii=False, indent=2)

# 替换为你的文件夹路径
folder_path = r"D:\pythonproject\lmv3-test"
process_images(folder_path)
# bbox,words=perform_ocr("img2.jpg")
print(1)
```

