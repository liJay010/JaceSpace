# layoutLM3训练问题解决

## 0.环境配置

严格按照如下配置，特别是torch1.10，且尽量cuda等于11.1

[unilm/layoutlmv3 at master · microsoft/unilm · GitHub](https://github.com/microsoft/unilm/tree/master/layoutlmv3)

```sh
pip install setuptools==59.5.0
pip install protobuf==3.20.1  -i https://pypi.douban.com/simple/
```

【448，448】 -\> (1,3,1088,768)

【224，224】 -\> (1,3,1088,768)

## 1.数据集配置

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/train_net.py

中修改注册数据集，COCO数据集

```py
    #注释其他数据集
    
 register_coco_instances("publaynet_train", {}, "/data1/lxj/workspace/layout/dataset/COCO/train/annotations.json", "/data1/lxj/workspace/layout/dataset/COCO/train")
    register_coco_instances("publaynet_val", {}, "/data1/lxj/workspace/layout/dataset/COCO/val/annotations.json", "/data1/lxj/workspace/layout/dataset/COCO/val")



```

## 2.训练

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml

NUM_CLASSES: 10

IMS_PER_BATCH: 1

```sh
cd /data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection


python train_net.py --config-file cascade_layoutlmv3.yaml --num-gpus 4 MODEL.WEIGHTS /data1/lxj/workspace/layout/model/layoutlmv3-base-chinese/pytorch_model.bin OUTPUT_DIR /data1/lxj/workspace/layout/output/12-14
```



# 3.batchsize以及step

**源论文：**

**16GPU**（具体不知道）

PubLayNet数据集：335,703图像

batchsize：32

step：60000，1,000 warmup

eopch约6轮



420 2080ti：

CDLA_DATASET：5000训练图像

4张卡一共能设置最大batchsize：4

step：60000，1,000 warmup



# 4.测试

测试中需要json文件

```sh
python train_net.py --config-file cascade_layoutlmv3.yaml --eval-only --num-gpus 4 \
        MODEL.WEIGHTS /data1/lxj/workspace/layout/output/model_final.pth \
        OUTPUT_DIR /data1/lxj/workspace/layout/output/val
```

# 5.网络问题

```sh
export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890
```

# 6.多模态训练方法

## 1.更改backbone.py

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/ditod/backbone.py

```py
#self.backbone = LayoutLMv3Model(config, detection=True,
#                                   out_features=out_features, image_only=image_only)
#将image_only改为false
self.backbone = LayoutLMv3Model(config, detection=True,
                                   out_features=out_features,image_only=False)
```

## 2.更改rcnn_vl.py

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/ditod/rcnn_vl.py

```py
def allgen(examples):
    align_size = max([i['input_id'].shape[0] for i in examples])
    for i in range(len(examples)):
        if len(examples[i]['input_id']) < align_size:
            pad_size = align_size - len(examples[i]['input_id'])
            examples[i]['input_id'] = torch.cat((examples[i]['input_id'], torch.ones(pad_size)))

        # 对 box 进行填充
        if len(examples[i]['box']) < align_size:
            pad_size = align_size - len(examples[i]['box'])
            padding = torch.zeros(pad_size, 4)
            examples[i]['box'] = torch.cat((examples[i]['box'], padding))
    return examples
#将get_batch函数替换
def get_batch(self, examples, images):

    if len(examples) >= 1 and "bbox" not in examples[0]:  # image_only
		#需要与最大的长度对齐 使用1 和[0,0,0,0]，
        examples = allgen(examples)
        ids = torch.stack([i['input_id'].long() for i in examples],dim=0).to(images.device)
        box = torch.stack([i['box'].long() for i in examples],dim=0).to(images.device)
        return {"images": images.tensor,"input_ids":ids,"bbox":box}

    return input
```

## 3.更改dataset_mapper.py

/data1/lxj/workspace/layout/unilm/layoutlmv3/examples/object_detection/ditod/dataset_mapper.py

```py
import os
import json
from transformers import AutoTokenizer

def normalize_box(box, width, height):
    return [
        max(int(1000 * (box[0] / width)),1000),
        max(int(1000 * (box[1] / height)),1000),
        max(int(1000 * ((box[0] + box[2]) / width)),1000),
        max(int(1000 * ((box[1] + box[3]) / height)),1000),
    ]
def read_OCRFile(image_path,reverseLen,removeStart = False):
    file_name, _ = os.path.splitext(os.path.basename(image_path))
    # 构建新路径，省略"JPEGImages"文件夹
    json_path = os.path.join(os.path.dirname(os.path.dirname(image_path)), "OCR", file_name + ".json")

    # 读取 JSON 文件
    with open(json_path, 'r', encoding='utf-8') as json_file:
        data = json.load(json_file)
    #一个words对应一个box
    box = [normalize_box(i,data['W'],data['H']) for i in data['bbox']]
    resbox = []
    input_idx = []
    tokenizer=AutoTokenizer.from_pretrained("/rxhui/lxj/workspace/project/unilm-master/layoutlmv3/examples/layout-Chinese")
    for li in range(len(box)):
        tokens=tokenizer.tokenize(data['words'][li])
        token_ids = tokenizer.convert_tokens_to_ids(tokens)
        cur_CNT = min(len(tokens),reverseLen)

        for wod in range(cur_CNT):
            #如果以6开始则remove
            if removeStart and token_ids[wod] == 6 and cur_CNT > 1:
                continue
            resbox.append(box[li])
            input_idx.append(token_ids[wod])
    if len(input_idx) == 0:
        return [1],[[0,0,0,0]]
    return input_idx,resbox



input_id,box = read_OCRFile(dataset_dict["file_name"],3,True) #3是取前几个token,True是第一个token为6则去掉
dataset_dict["input_id"] = torch.tensor(input_id) #这里是输入的ids
dataset_dict["box"] = torch.tensor(box)#这里是输入的box
```

## 4.中文的token分词器

```py
from transformers import AutoTokenizer

tokenizer=AutoTokenizer.from_pretrained("yuyijiong/layoutlmv3-base-chinese-xfund")
tokens=tokenizer.tokenize("你好，我叫李兴杰")
token_ids = tokenizer.convert_tokens_to_ids(tokens)
print(token_ids)

#tokenizer.convert_tokens_to_string(tokens)
#tokenizer.encode(sentence)
#tokenizer.decode(token_ids,skip_special_tokens=False)
```

## 5.OCR

```py
import os
from PIL import Image
import json
from paddleocr import PaddleOCR, draw_ocr
ocr = PaddleOCR(use_angle_cls=True, lang="ch")
def perform_ocr(image_path):
    # 假设这里调用你的OCR函数并返回bbox和words列表
    # 实际情况需要替换为你的OCR函数调用
    print("process:"+image_path)
    result = ocr.ocr(image_path, cls=True)
    result = result[0]

    bbox=[[line[0][0][0],line[0][0][1],line[0][2][0]-line[0][0][0],line[0][2][1]-line[0][0][1]] for line in result]

    words = [line[1][0] for line in result] # 示例words
    return bbox, words

def process_images(folder_path):
    for filename in os.listdir(folder_path):
        if filename.endswith(('.jpg', '.jpeg', '.png')):  # 假设你处理的是图片文件
            image_path = os.path.join(folder_path, filename)

            # 调用OCR函数
            bbox, words = perform_ocr(image_path)

            # 获取图片分辨率
            with Image.open(image_path) as img:
                w, h = img.size

            # 构建结果字典
            result = {
                    "bbox": bbox,
                    "words": words,
                    "W": w,
                    "H": h
            }

            # 保存为JSON文件
            json_filename = os.path.splitext(filename)[0] + ".json"
            json_path = os.path.join(folder_path, json_filename)

            with open(json_path, 'w',encoding='utf-8') as json_file:
                json.dump(result, json_file, ensure_ascii=False, indent=2)

# 替换为你的文件夹路径
folder_path = r"D:\pythonproject\lmv3-test"
process_images(folder_path)
# bbox,words=perform_ocr("img2.jpg")
print(1)
```

